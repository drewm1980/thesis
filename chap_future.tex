\section{Introduction}

%solving this problem (speed) will be a major
%component of the remaining work for my proposed Ph.D. thesis.  Another major
%component of my research will be a systematic study of the choice of training
%illuminations.  Having already implemented a novel projector based training
%image acquisition system, I have the unique chance to automate the optimization
%of the set of training illuminations.  Another major step will be to combine
%the Markov Random Field occlusion handling with our iterative alignment
%algorithm.  Finally, there are some improvements that could be made to the
%training acquisition hardware itself to improve training image acquisition.  

%\section{Optimizing the Speed of the Recognition Algorithm}

%\begin{table}[h]
%\centering
%\begin{tabular}{|c|c|}
%\hline
%Operation & Execution Time (seconds)\\
%\hline
%Loading the training database & 74\\
%\hline
%Per-user alignment & 130\\
%\hline
%Resampling the training images & 18\\
%\hline
%Final recognition step &137\\
%\hline
%\end{tabular}\vspace{2mm}
%\caption{Execution timing for a database of 100 training users with 30 xga grayscale training images per user} \label{tab:breakdown}
%\end{table}

\subsection{Loading the training database}  

One strategy for reducing the latency of the image loading is to use a
technology called memory mapping.  This creates a mapping between the data in a
file in the system (most of which will be resident on the hard drive) and the
address space of the program.  The operating system's virtual memory system
then handles the loading of data from disk into RAM as needed when the program
access the corresponding addresses in its memory space.  This technique has the
potential to kill several birds with one stone:
\begin{itemize}
\item Since there is one virtual memory system for all processes in the os,
portions of the database that are used by multiple processes can share the data
that has been loaded into RAM.  This can significantly reduce the memory
footprint when multiple instances of the recognition system are running
simultaneously.
\item It is much easier to load just the portion of each image file that is
needed.  Resampling the training images will only require a subset of the
pixels from the high resolution image.  On x86 systems the memory page size is
2KB.  For a grayscale xga image laid out linearly one disk this corresponds to
two rows of the image.  In this case only the rows that overlap the user's face
will get loaded from disk into memory.  This can be improved further by laying
out the data so that each memory corresponds to a tile of about 45 x 45 pixels.
Then only the tiles that overlap the users' face will have to get loaded into
memory.
\item There is a mechanism to hint to the operating system what data will be
needed in advance so that is can be pre-loaded.  
\end{itemize} 
Another strategy for reducing the latency of the image loading is to try to
predict which images will need to be loaded in advance of when they are used.
In particular, we have some information about which users will likely make the
cut for the recognition step while per-user alignment is still being performed.
Any training user that is not in the top $S$ (currently set to 10) users
aligned so far certainly need not be loaded into memory.  

\subsection{Resampling the training images}  
One strategy for reducing the amount of time spent resampling(warping) the
training images is to make use of the fact that we are resampling $N$ (= 38
training images currently) simultaneously with the same transformation. 
In other words, the training images can be treated as a single 38 color image.
This this has the potential to speed up the resampling stage for two reasons:
first, it avoids re-computation of the mapping of pixel locations, and second,
the memory accesses have improved cache locality.
Unfortunately, optimized third party libraries such as Intel's Integrated Performance
Primitives rarely provide optimized image
transformations for images of more than four colors.

\section{Optimizing the training illuminations} 
To date, I have performed two experiments have been performed to guide the
choice of training illuminations, the results of which were shown in Chapter
\ref{chap:cvpr}.  One used rectangular partitions of the domain of the
illumination space with different granularities.  This gave a rough idea of the
number of training illuminations that would be necessary.  The second
experiment used a partitions of the illumination domain that were rectangular
in a polar coordinate system.  This gave a rough idea of the range of angles
the training images should cover.  Our large training database was acquired by
combining these two pieces of information.  While a study of the choice of
training illuminations at this granularity is already unprecedented for face
recognition, \footnote{ Several studies, including \cite{Basri2003-PAMI,
LeeK2005-PAMI} have used images rendered from a 3D face model to optimize their
choice of illumination.  Similar illumination studies have also been performed
on other objects for graphics applications.} only a very small subset of the
possible illuminations was explored compared to what the projectors are capable
of.  For instance, how many of the frontal images are necessary?  Should some
directions receive a higher density of illuminations than others? 

\subsection{Optimize illuminations within the set of training images we already have}
One option we have for optimizing our training illuminations is to use the
training and testing databases we have already gathered, and to search for a
lower dimensional subspace of illuminations that still has a good recognition
rate.  The two main advantages of this strategy are that the recognition rate
can be computed directly and used as a measure of the quality of the training
images, and that the sizable database we have already gathered can be used.
The main disadvantage is that we will most likely have to trade some accuracy
for speed, since we can only restrict the number of measurements the algorithm
uses. \footnote{It could be possible for a subset of the illuminations is more
discriminating than the full set; however this would be a very surprising
result indeed!}

\subsection{Optimize illuminations with the illumination system in the loop}
A second option is to perform an optimization of the training image space with
the image acquisition system in the loop.  The main advantage is that we can
include any training images we want to in the optimizaztion.  The main
disadvantage is that we cannot compute a recognition rate and instead have to
resort to using representation error as a measure of the quality of the
training images.  Why can't we just capture and store a the images generated by
a complete basis for the space of illuminations, and then optimize over
weighted combinations of them?  If a single projector pixel is illuminated at a
time, it would take over 4 TB of data to store the remaining images, and take
28 hours to capture; this wouldn't be convenient, but it could be managed.
Unfortunately, there is a problem with this idea:  in every image you take, the
actual signal would fall below the noise floor of the camera.  For this reason
it is critical to capture images with a significant portion of the projector
pixels illuminated at a time.  Keeping the real world in the loop solves this
problem without resorting to arbitrarily enforcing a minimum block size.  Due
to the extremely long time that the subject will have to remain motionless
while the optimization runs, a movie-grade dummy head would be a good candidate
for the training subject.  

This still leaves several interesting questions.  Even with an automated search, we are going to have to make some assumptions to reduce the search space.  Should we allow for pixels to be partially turned on, or should they be binary?  Should we require illuminations to have pixels that are all adjacent?  What metric should we use to measure the quality of the training images?  Ideally we'd be using a large database of real subjects, but that is not an option if we want to search over the full set of illuminations the projectors can generate.  How many training images should we allow?  How do we quantify the tradeoff between speed and accuracy?

There are few other things that make this experiment appealing.  Since the dummy head is inanimate, we will completely eliminate the influence of pose variation on the experiment, and all of our training images will already be perfectly aligned; the cameras can be manually positioned such that the frontal and rear illuminations match up perfectly. \footnote{Since we want to capture training illuminations from both sides, the dummy head can be mounted on a stepper-motor driven pivot for the purpose of rotating the dummy head by 180 degrees.  }

\subsection{Leverage color information to improve occlusion robustness}  Color information is unused for the current system.  This was a simplifying assumption that made implementation of the algorithm significantly easier and faster.  There are several different ways in which the algorithms presented in this thesis could be extended to handle color information.  One of the main reasons that color is not as important in face recognition as it is in some other vision applications is that the pixels in the image of a given person's face generally vary primarily in intensity.  Furthermore, the variation of skin tone from person to person usually varies less than the color variation resulting from the color of the illumination.  For these reasons, color may be especially useful for the improvement of occlusion handling, since occluding objects are likely to vary in color more than human faces do.  


\section{Combining MRF recognition with alignment} Chapter \ref{chap:iccv} demonstrated that it is possible to improve recognition performance by leveraging the information that occlusions are typically spatially coherent.  However, all of the experiments were performed on images that had already been aligned.  Combining this technique with alignment is an important topic for further research, and my collaboration with Zihan Zhou will continue on this topic.  The first attempt at integrating the MRF extension with alignment will be a straightforward combination of the two ideas.  Alignment is achieved by including a linearization of the warped test image with respect to the transformation parameters in the L1 optimization.  MRF simply restricts the subset of pixels on which the L1 optimization is performed.  Therefore, these two ideas are neatly orthogonal from an implementation standpoint.  The challenging part will be to understand exactly how the alignment and occlusion rejection interact in the early iterations of the algorithm, where the estimates of both the occlusion and the alignment have not yet converged significantly.


\section{Improving the acquisition system hardware}
The current design has proven to be very satisfactory in a research environment where the subjects are very cooperative and make an effort to hold very still while the images are being taken.  Unfortunately, not all users of this technology will be so careful.  The best way to improve the quality of the training images is to increase the speed at which they are acquired.  The primary motive for this is to reduce the amount of movement of the user's head between consecutive training images.  There are several possible ways in which this goal can be pursued:
%{\bf Refinements to the current design}
\begin{itemize}
\item {\em Increase the image acquisition rate by upgrading the cameras.}  Some newer IEEE1394 cameras contain features that could facilitate this.  One is the ability to trigger off of an external signal while still interleaving image exposure with transfer of the previous frame over the bus.  With our current cameras transfer and integration is serialized.  
\item {\em Implementing some type automatic exposure control}  Some illuminations cause more light to fall on the subject's face than others.  Therefore, the optimal exposure time depends on which illumination is being displayed.  Automatic compensation for this could reduce the average exposure time without hurting the SNR.
\item {\em Reduce synchronization delays by modifying the projectors}  There is a clock signal that drives the switching of the Digital Micromirror Device in each projector.  Synchronizing the camera exposure with a whole number of projector frames would greatly increase acquisition time; currently we have to be very conservative with the amount of time a given illumination is displayed to prevent problems synchronizing with the camera.
\item {\em Reduce exposure time by modifying the projectors}  The only way to decrease the exposure time without hurting signal to noise ratio is to increase the intensity of the lighting.  Most DLP projectors achieve color by spinning a wheel with either a colored mirror or a transmissive color filters in front of the light source.  Since color is not needed for  the training image acquisition, it would be desirable to remove the color wheel, effectively turning the projector into a black and white projector with a higher maximum intensity.
\end{itemize}
Not all of the above strategies may turn out to be feasible; in particular, the last two ideas would require some degree of reverse engineering of proprietary hardware inside the projector.  While the modifications are conceptually very simple, there may be unforeseen difficulties depending on the design of the projector.  In the worst case, the manufacturer may have deliberately implemented features to prevent tampering.

% TODO Mention scheneker illumination patterns.

%{\bf Radical departures from the current design}
%The training image acquisition system detailed in Chapter \ref{chap:cvpr} requires several reasonably high quality DLP projectors and cameras for its operation.  While this is an investment that a large institution using face recognition  for access control might be willing to make, it pretty much rules outs application in less mission critical applications. There are several substitute techniques that may be worth pursuing:
%\begin{itemize}
%\item {\em Replace the projectors with many smaller light sources}  The main disadvantage of this technique is that it necessitates either building a large structure to hold the light sources or mounting them on the walls and ceiling.  Either way, a network of wires will be required to power and the actuate the lights, which further complicates installation.
%\item {\em Replace the projectors with a moving light source}  The main reason the projectors are not very cost effective in this application is that most of the light they produce is wasted.  This dramatically increases the need for thermal design, reduces the life of the components, and increases the power usage.  There are a variety of possible designs that get around this including the use of a moving light source, moving light-directing mirrors, or an array of focused light sources.
%\item {\em Replace the projectors with ambient lighting}  One face recognition application that has already hit the market is for securing user login on laptops.  Unfortunately, most individual users won't have access to a system that takes many pictures of them under controlled lighting.  One potential solution to this could be to have the user turn on a single light in their room, and then turn around in a circle while holding their (camera equipped) laptop.  The biggest hurdle for this technique will be that the training images will need to be aligned, since the user's head will likely move significantly during use.
%\end{itemize} 

\section{Conclusion}
Accelerating the algorithm to the point where it can be used for access control
will initially be the highest priority.  Almost all parts of the algorithm will
need to be re-implemented to take advantage of hardware specific optimizations
on a new architecture, and this will be a major undertaking.  However this is
effort is necessary not only to demonstrate that the recognition system can be
applied to access control, but also so that the L1 optimization routines we use
can be useful to others in the vision community.  Furthermore a faster
implementation will enable me to perform experiments in the optimization of the
training illuminations at a granularity that has never been attempted before.
It will be very interesting to see how much a more thoroughly optimized set of
training illuminations can improve the recognition rate, and what those
illuminations look like.  If the optimization of the training illuminations
reliably converges to a particular set of illuminations, this work could settle
once and for all how training illuminations for face recognition should be
selected.  The robustness of the recognition algorithm to occlusions can likely
be improved by integrating our new MRF results with our existing iterative
alignment algorithm, and the quality of the training images can be improved
through improved hardware integration.  The overall goal of the project is to
deliver a face recognition system that is easy to implement, is robust to
illumination variation, mild occlusions, and mild pose variations, and is
scalable up to hundreds of users.
